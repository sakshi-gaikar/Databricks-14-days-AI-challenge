{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f61291f1-0e75-413d-a79f-62145d0ea9ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **DAY 13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "905c7f55-4c90-4c6d-a61c-b2fc5eaea753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/23 14:54:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regression: R² Score = 0.6578\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/23 14:54:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree: R² Score = 0.6919\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2026/01/23 14:56:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: R² Score = 0.6152\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 1️⃣ Load data from GOLD\n",
    "df = spark.table(\"gold.daily_product_metrics\").toPandas()\n",
    "\n",
    "# 2️⃣ Prepare features and target\n",
    "X = df[[\"views\", \"cart_adds\"]]\n",
    "y = df[\"purchases\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3️⃣ Models\n",
    "models = {\n",
    "    \"linear_regression\": LinearRegression(),\n",
    "    \"decision_tree\": DecisionTreeRegressor(max_depth=5),\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 4️⃣ MLflow training\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        score = model.score(X_test, y_test)\n",
    "        mlflow.log_metric(\"r2_score\", score)\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"{name}: R² Score = {score:.4f}\")\n",
    "# Spark ML Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression as SparkLR\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"views\",\"cart_adds\"], outputCol=\"features\")\n",
    "lr = SparkLR(featuresCol=\"features\", labelCol=\"purchases\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "spark_df = spark.table(\"gold.daily_product_metrics\")\n",
    "train, test = spark_df.randomSplit([0.8, 0.2])\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3817686-0b53-477f-a1aa-9ec3cb15d216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5346836060260434,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY13",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}